{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make RNN learn to perform addition\n",
    "\n",
    "改寫https://github.com/keras-team/keras/blob/master/examples/addition_rnn.py\n",
    "\n",
    "手法為sequence to sequence learning\n",
    "\n",
    "而目標為例如輸入535+61, 希望輸出為596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, LSTM, Input, RepeatVector, TimeDistributed\n",
    "from keras.activations import softmax\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable():\n",
    "    def __init__(self, chars):\n",
    "        \"\"\" 製造char->int以及int->char的對應\n",
    "        @ Args:\n",
    "            chars(str): 所有可能的輸入\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "    \n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\" 將給定的string C做one-hot encoding\n",
    "        @ Args:\n",
    "            C(str): 要做encoding的string\n",
    "            num_rows(int): 即可能的輸入個數, 比如數字有10種可能, 此即為10\n",
    "        @ returns:\n",
    "            x(np.array): C的每個char經過encoding後的結果(num_rows x len(C))\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        \"\"\" 將int轉換回char\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_TRAINING_SAMPLES = 50000 # number of addition questions\n",
    "NB_DIGITS = 3 # input number in [0 - 999]\n",
    "REVERSE = True # like data augmentation, we have 535+61 and then we'll train 61+535 too\n",
    "MAX_STRING_LENGTH = NB_DIGITS*2 + 1 # for '345+678', then length is 3*2+1=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chars = '0123456789+ ' # 所有char的可能(12個)\n",
    "char_table = CharacterTable(all_chars) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [] # 所有問題, 如'123+456'\n",
    "answers = [] # 答案, 如579\n",
    "seen = set() # 出現過的問題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXIMUM = 10**NB_DIGITS-1\n",
    "while len(questions) < NB_TRAINING_SAMPLES:\n",
    "    a = np.random.randint(0, MAXIMUM)\n",
    "    b = np.random.randint(0, MAXIMUM)\n",
    "    q1 = str(a) + '+' + str(b)\n",
    "    # 這種放法nn可以簡單的知道\"非空白之後高機率是非空白\", 若調換則NN要多學判斷數字斷點的方式\n",
    "    q1 = ' '*(MAX_STRING_LENGTH - len(q1)) + q1\n",
    "    q2 = str(b) + '+' + str(a)\n",
    "    q2 = ' '*(MAX_STRING_LENGTH - len(q2)) + q2\n",
    "    if q1 in seen:\n",
    "        continue\n",
    "    seen.add(q1)\n",
    "    ans = str(eval(q1))\n",
    "    questions.append(q1)\n",
    "    # 類似前面的方式, 這樣擺的話NN知道\"空白之後高機率是空白\"\n",
    "    # 不過我沒驗證  或許實際上沒差?\n",
    "    answers.append(ans + ' '*(NB_DIGITS+1-len(ans)))\n",
    "    \n",
    "    if REVERSE:\n",
    "        seen.add(q2)    \n",
    "        ans = str(eval(q2))        \n",
    "        questions.append(q2)            \n",
    "        answers.append(ans + ' '*(NB_DIGITS+1-len(ans)) )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The shape of x:\n",
    "[問題數, 問題最大長度(即RNN的輸入長度), 所有的字符數(即one-hot向量的長度)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(shape=(len(questions), MAX_STRING_LENGTH, len(all_chars)), dtype=np.bool)\n",
    "# NB_DIGITS+1: 三位數+三位數最多變四位數\n",
    "y = np.zeros(shape=(len(questions), NB_DIGITS+1, len(all_chars)), dtype=np.bool)\n",
    "\n",
    "for i, expression in enumerate(questions):\n",
    "    x[i] = char_table.encode(expression, MAX_STRING_LENGTH)\n",
    "for i, answer in enumerate(answers):\n",
    "    y[i] = char_table.encode(answer, NB_DIGITS+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_order = np.arange(len(questions))\n",
    "np.random.shuffle(random_order)\n",
    "\n",
    "x = x[random_order]\n",
    "y = y[random_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "split_index = int(0.9*len(questions))\n",
    "train_x, val_x = x[:split_index], x[split_index:]\n",
    "train_y, val_y = y[:split_index], y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128 # lstm中hidden units的數目\n",
    "NB_LSTM_LAYERS_WITH_SEQ_OUTPUT = 1 # encoder後串接的lstm層數\n",
    "RNN_MODEL = LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     (None, 7, 12)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 4, 12)             1548      \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# input shape即為MAX_STRING_LENGTH(此例為3+3+1=7) x encoding長度(所有char的數目, 此例為12)\n",
    "model_input = Input(shape=train_x.shape[1:], name='input_layer')\n",
    "# 此處lstm遞迴MAX_STRING_LENGTH次, 並且只輸出這整個字串的encoder結果, 並不輸出sequence\n",
    "rnn = RNN_MODEL(units=HIDDEN_SIZE)(model_input)\n",
    "# 將上面結果重複NB_DIGITS+1次後再丟到LSTM中, 並且輸出sequence\n",
    "# 即我們最終的目標是預測一個最長可能有NB_DIGITS+1的數字(e.g. 600+500=1100)\n",
    "rnn = RepeatVector(NB_DIGITS+1)(rnn)\n",
    "for _ in range(NB_LSTM_LAYERS_WITH_SEQ_OUTPUT):\n",
    "    rnn = RNN_MODEL(HIDDEN_SIZE, return_sequences=True)(rnn)\n",
    "# 現在依照初始的架構, 此處的shape為NB_DIGITS x HIDDEN_SIZE\n",
    "# TimeDistributed對NB_DIGITS+1個資料分別建立一個NN\n",
    "# 也就是TimeDistributed分配的網路數=RNN遞迴次數=輸出的sequence長度=NB_DIGITS+1\n",
    "# 此目的在於將每個time step的資訊分開, 如最後面的圖的decoder部分中Dense彼此沒有連接\n",
    "# 若沒有這個步驟, 則所有time step的資訊將會混在一起\n",
    "# 由於每個char都有12種可能, 因此Dense的hidden unit數目為len(all_chars)=12\n",
    "prediction = TimeDistributed(Dense(len(all_chars), activation='softmax'))(rnn)\n",
    "model = Model(inputs=[model_input], outputs=[prediction])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 21s 467us/step - loss: 1.6182 - acc: 0.4023 - val_loss: 1.4095 - val_acc: 0.4583\n",
      "Q 575+356 T 1228 \u001b[91m☒\u001b[0m 1227\n",
      "Q 337+237 T 1465 \u001b[91m☒\u001b[0m 1402\n",
      "Q 679+984 T 1465 \u001b[91m☒\u001b[0m 1577\n",
      "Q 366+63  T 699  \u001b[91m☒\u001b[0m 700 \n",
      "Q 629+693 T 1322 \u001b[91m☒\u001b[0m 1300\n",
      "Q 446+221 T 766  \u001b[91m☒\u001b[0m 707 \n",
      "Q 268+136 T 1493 \u001b[91m☒\u001b[0m 1472\n",
      "Q 388+92  T 912  \u001b[91m☒\u001b[0m 900 \n",
      "Q 299+159 T 1943 \u001b[91m☒\u001b[0m 1777\n",
      "Q 6+476   T 680  \u001b[91m☒\u001b[0m 707 \n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 426us/step - loss: 1.1247 - acc: 0.5770 - val_loss: 0.9865 - val_acc: 0.6322\n",
      "Q 675+519 T 1491 \u001b[91m☒\u001b[0m 1499\n",
      "Q 341+846 T 791  \u001b[91m☒\u001b[0m 794 \n",
      "Q 132+91  T 250  \u001b[91m☒\u001b[0m 210 \n",
      "Q 319+472 T 1187 \u001b[91m☒\u001b[0m 1177\n",
      "Q 079+713 T 1287 \u001b[91m☒\u001b[0m 1299\n",
      "Q 331+981 T 322  \u001b[91m☒\u001b[0m 214 \n",
      "Q 291+516 T 807  \u001b[91m☒\u001b[0m 704 \n",
      "Q 197+94  T 840  \u001b[91m☒\u001b[0m 844 \n",
      "Q 035+122 T 751  \u001b[91m☒\u001b[0m 759 \n",
      "Q 119+525 T 1436 \u001b[91m☒\u001b[0m 1446\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 427us/step - loss: 0.7673 - acc: 0.7122 - val_loss: 0.6214 - val_acc: 0.7650\n",
      "Q 07+773  T 447  \u001b[92m☑\u001b[0m 447 \n",
      "Q 161+767 T 928  \u001b[92m☑\u001b[0m 928 \n",
      "Q 363+383 T 746  \u001b[91m☒\u001b[0m 748 \n",
      "Q 796+898 T 1595 \u001b[91m☒\u001b[0m 1583\n",
      "Q 617+657 T 1472 \u001b[91m☒\u001b[0m 1473\n",
      "Q 346+664 T 1109 \u001b[91m☒\u001b[0m 1119\n",
      "Q 418+131 T 945  \u001b[92m☑\u001b[0m 945 \n",
      "Q 377+582 T 1058 \u001b[91m☒\u001b[0m 1057\n",
      "Q 74+619  T 963  \u001b[91m☒\u001b[0m 969 \n",
      "Q 818+064 T 1278 \u001b[91m☒\u001b[0m 1279\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 432us/step - loss: 0.3234 - acc: 0.8923 - val_loss: 0.2812 - val_acc: 0.9066\n",
      "Q 468+199 T 1855 \u001b[91m☒\u001b[0m 1856\n",
      "Q 917+73  T 756  \u001b[91m☒\u001b[0m 766 \n",
      "Q 446+221 T 766  \u001b[92m☑\u001b[0m 766 \n",
      "Q 897+696 T 1494 \u001b[92m☑\u001b[0m 1494\n",
      "Q 433+263 T 696  \u001b[92m☑\u001b[0m 696 \n",
      "Q 81+305  T 521  \u001b[91m☒\u001b[0m 511 \n",
      "Q 943+391 T 542  \u001b[91m☒\u001b[0m 552 \n",
      "Q 008+801 T 908  \u001b[92m☑\u001b[0m 908 \n",
      "Q 853+968 T 1227 \u001b[92m☑\u001b[0m 1227\n",
      "Q 658+013 T 1166 \u001b[91m☒\u001b[0m 1165\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 428us/step - loss: 0.1140 - acc: 0.9668 - val_loss: 0.0775 - val_acc: 0.9768\n",
      "Q 383+386 T 1066 \u001b[91m☒\u001b[0m 1056\n",
      "Q 979+376 T 1652 \u001b[92m☑\u001b[0m 1652\n",
      "Q 309+865 T 1471 \u001b[92m☑\u001b[0m 1471\n",
      "Q 298+401 T 996  \u001b[92m☑\u001b[0m 996 \n",
      "Q 477+118 T 1585 \u001b[92m☑\u001b[0m 1585\n",
      "Q 292+92  T 321  \u001b[92m☑\u001b[0m 321 \n",
      "Q 607+327 T 1429 \u001b[91m☒\u001b[0m 1439\n",
      "Q 568+246 T 1507 \u001b[92m☑\u001b[0m 1507\n",
      "Q 668+301 T 969  \u001b[92m☑\u001b[0m 969 \n",
      "Q 703+188 T 1188 \u001b[92m☑\u001b[0m 1188\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 415us/step - loss: 0.0779 - acc: 0.9768 - val_loss: 0.0587 - val_acc: 0.9809\n",
      "Q 078+071 T 1040 \u001b[92m☑\u001b[0m 1040\n",
      "Q 01+699  T 1006 \u001b[92m☑\u001b[0m 1006\n",
      "Q 495+196 T 1285 \u001b[92m☑\u001b[0m 1285\n",
      "Q 449+009 T 1844 \u001b[92m☑\u001b[0m 1844\n",
      "Q 381+214 T 595  \u001b[92m☑\u001b[0m 595 \n",
      "Q 413+065 T 874  \u001b[92m☑\u001b[0m 874 \n",
      "Q 559+753 T 1312 \u001b[92m☑\u001b[0m 1312\n",
      "Q 635+206 T 1138 \u001b[92m☑\u001b[0m 1138\n",
      "Q 663+87  T 444  \u001b[92m☑\u001b[0m 444 \n",
      "Q 04+794  T 537  \u001b[92m☑\u001b[0m 537 \n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 415us/step - loss: 0.0589 - acc: 0.9822 - val_loss: 0.1669 - val_acc: 0.9461\n",
      "Q 194+392 T 784  \u001b[92m☑\u001b[0m 784 \n",
      "Q 658+453 T 1210 \u001b[92m☑\u001b[0m 1210\n",
      "Q 938+224 T 1261 \u001b[91m☒\u001b[0m 1271\n",
      "Q 201+336 T 735  \u001b[92m☑\u001b[0m 735 \n",
      "Q 884+503 T 793  \u001b[92m☑\u001b[0m 793 \n",
      "Q 155+158 T 1402 \u001b[91m☒\u001b[0m 1412\n",
      "Q 878+069 T 1838 \u001b[91m☒\u001b[0m 1738\n",
      "Q 687+057 T 1536 \u001b[92m☑\u001b[0m 1536\n",
      "Q 463+439 T 1298 \u001b[92m☑\u001b[0m 1298\n",
      "Q 53+979  T 1014 \u001b[92m☑\u001b[0m 1014\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 417us/step - loss: 0.0484 - acc: 0.9850 - val_loss: 0.0330 - val_acc: 0.9890\n",
      "Q 758+423 T 1181 \u001b[92m☑\u001b[0m 1181\n",
      "Q 77+804  T 485  \u001b[91m☒\u001b[0m 484 \n",
      "Q 63+404  T 440  \u001b[91m☒\u001b[0m 430 \n",
      "Q 092+802 T 498  \u001b[92m☑\u001b[0m 498 \n",
      "Q 518+415 T 1329 \u001b[92m☑\u001b[0m 1329\n",
      "Q 078+742 T 1117 \u001b[92m☑\u001b[0m 1117\n",
      "Q 163+068 T 1221 \u001b[92m☑\u001b[0m 1221\n",
      "Q 316+945 T 1162 \u001b[92m☑\u001b[0m 1162\n",
      "Q 946+111 T 760  \u001b[92m☑\u001b[0m 760 \n",
      "Q 596+584 T 1180 \u001b[92m☑\u001b[0m 1180\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 421us/step - loss: 0.0455 - acc: 0.9860 - val_loss: 0.0272 - val_acc: 0.9917\n",
      "Q 203+567 T 1067 \u001b[92m☑\u001b[0m 1067\n",
      "Q 531+977 T 914  \u001b[92m☑\u001b[0m 914 \n",
      "Q 117+496 T 1405 \u001b[92m☑\u001b[0m 1405\n",
      "Q 344+65  T 499  \u001b[92m☑\u001b[0m 499 \n",
      "Q 984+368 T 1352 \u001b[92m☑\u001b[0m 1352\n",
      "Q 71+375  T 590  \u001b[92m☑\u001b[0m 590 \n",
      "Q 198+005 T 1391 \u001b[92m☑\u001b[0m 1391\n",
      "Q 002+09  T 290  \u001b[92m☑\u001b[0m 290 \n",
      "Q 35+29   T 145  \u001b[92m☑\u001b[0m 145 \n",
      "Q 578+829 T 1803 \u001b[92m☑\u001b[0m 1803\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 415us/step - loss: 0.0400 - acc: 0.9876 - val_loss: 0.0810 - val_acc: 0.9719\n",
      "Q 531+526 T 760  \u001b[92m☑\u001b[0m 760 \n",
      "Q 644+14  T 487  \u001b[92m☑\u001b[0m 487 \n",
      "Q 758+323 T 1180 \u001b[92m☑\u001b[0m 1180\n",
      "Q 757+469 T 1721 \u001b[92m☑\u001b[0m 1721\n",
      "Q 222+097 T 1012 \u001b[92m☑\u001b[0m 1012\n",
      "Q 931+173 T 510  \u001b[92m☑\u001b[0m 510 \n",
      "Q 564+615 T 981  \u001b[92m☑\u001b[0m 981 \n",
      "Q 106+302 T 804  \u001b[92m☑\u001b[0m 804 \n",
      "Q 803+696 T 1004 \u001b[92m☑\u001b[0m 1004\n",
      "Q 255+981 T 741  \u001b[92m☑\u001b[0m 741 \n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 427us/step - loss: 0.0419 - acc: 0.9870 - val_loss: 0.0101 - val_acc: 0.9975\n",
      "Q 712+423 T 541  \u001b[92m☑\u001b[0m 541 \n",
      "Q 909+163 T 1270 \u001b[92m☑\u001b[0m 1270\n",
      "Q 212+707 T 919  \u001b[92m☑\u001b[0m 919 \n",
      "Q 709+078 T 1777 \u001b[92m☑\u001b[0m 1777\n",
      "Q 923+974 T 808  \u001b[92m☑\u001b[0m 808 \n",
      "Q 963+305 T 872  \u001b[92m☑\u001b[0m 872 \n",
      "Q 426+463 T 988  \u001b[92m☑\u001b[0m 988 \n",
      "Q 362+553 T 618  \u001b[92m☑\u001b[0m 618 \n",
      "Q 004+358 T 1253 \u001b[92m☑\u001b[0m 1253\n",
      "Q 702+781 T 394  \u001b[92m☑\u001b[0m 394 \n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 431us/step - loss: 0.0356 - acc: 0.9893 - val_loss: 0.0542 - val_acc: 0.9873\n",
      "Q 199+134 T 1422 \u001b[92m☑\u001b[0m 1422\n",
      "Q 471+701 T 281  \u001b[92m☑\u001b[0m 281 \n",
      "Q 815+818 T 1336 \u001b[92m☑\u001b[0m 1336\n",
      "Q 544+643 T 791  \u001b[92m☑\u001b[0m 791 \n",
      "Q 227+738 T 1559 \u001b[92m☑\u001b[0m 1559\n",
      "Q 259+372 T 1225 \u001b[92m☑\u001b[0m 1225\n",
      "Q 89+084  T 578  \u001b[92m☑\u001b[0m 578 \n",
      "Q 243+817 T 1060 \u001b[92m☑\u001b[0m 1060\n",
      "Q 487+547 T 1529 \u001b[92m☑\u001b[0m 1529\n",
      "Q 089+81  T 998  \u001b[92m☑\u001b[0m 998 \n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 20s 434us/step - loss: 0.0257 - acc: 0.9916 - val_loss: 0.0275 - val_acc: 0.9902\n",
      "Q 327+436 T 1357 \u001b[92m☑\u001b[0m 1357\n",
      "Q 879+913 T 1297 \u001b[92m☑\u001b[0m 1297\n",
      "Q 332+557 T 988  \u001b[92m☑\u001b[0m 988 \n",
      "Q 735+043 T 877  \u001b[92m☑\u001b[0m 877 \n",
      "Q 07+655  T 626  \u001b[92m☑\u001b[0m 626 \n",
      "Q 603+053 T 656  \u001b[92m☑\u001b[0m 656 \n",
      "Q 319+423 T 1237 \u001b[92m☑\u001b[0m 1237\n",
      "Q 974+026 T 1099 \u001b[92m☑\u001b[0m 1099\n",
      "Q 805+23  T 540  \u001b[92m☑\u001b[0m 540 \n",
      "Q 011+709 T 1017 \u001b[92m☑\u001b[0m 1017\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 425us/step - loss: 0.0364 - acc: 0.9891 - val_loss: 0.0264 - val_acc: 0.9911\n",
      "Q 066+026 T 1280 \u001b[92m☑\u001b[0m 1280\n",
      "Q 958+048 T 1699 \u001b[92m☑\u001b[0m 1699\n",
      "Q 091+271 T 362  \u001b[92m☑\u001b[0m 362 \n",
      "Q 124+477 T 1195 \u001b[92m☑\u001b[0m 1195\n",
      "Q 701+538 T 942  \u001b[92m☑\u001b[0m 942 \n",
      "Q 723+56  T 392  \u001b[92m☑\u001b[0m 392 \n",
      "Q 215+673 T 888  \u001b[92m☑\u001b[0m 888 \n",
      "Q 17+883  T 459  \u001b[92m☑\u001b[0m 459 \n",
      "Q 924+523 T 754  \u001b[92m☑\u001b[0m 754 \n",
      "Q 702+781 T 394  \u001b[92m☑\u001b[0m 394 \n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 433us/step - loss: 0.0255 - acc: 0.9920 - val_loss: 0.0241 - val_acc: 0.9916\n",
      "Q 079+713 T 1287 \u001b[92m☑\u001b[0m 1287\n",
      "Q 083+078 T 1250 \u001b[92m☑\u001b[0m 1250\n",
      "Q 245+981 T 731  \u001b[92m☑\u001b[0m 731 \n",
      "Q 98+288  T 971  \u001b[92m☑\u001b[0m 971 \n",
      "Q 618+437 T 1550 \u001b[92m☑\u001b[0m 1550\n",
      "Q 195+073 T 961  \u001b[92m☑\u001b[0m 961 \n",
      "Q 145+434 T 975  \u001b[92m☑\u001b[0m 975 \n",
      "Q 875+954 T 1037 \u001b[92m☑\u001b[0m 1037\n",
      "Q 901+073 T 479  \u001b[92m☑\u001b[0m 479 \n",
      "Q 775+973 T 956  \u001b[92m☑\u001b[0m 956 \n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 425us/step - loss: 0.0379 - acc: 0.9892 - val_loss: 0.0176 - val_acc: 0.9953\n",
      "Q 719+028 T 1737 \u001b[92m☑\u001b[0m 1737\n",
      "Q 211+733 T 449  \u001b[92m☑\u001b[0m 449 \n",
      "Q 485+783 T 971  \u001b[92m☑\u001b[0m 971 \n",
      "Q 905+389 T 1492 \u001b[92m☑\u001b[0m 1492\n",
      "Q 314+574 T 888  \u001b[92m☑\u001b[0m 888 \n",
      "Q 395+06  T 653  \u001b[92m☑\u001b[0m 653 \n",
      "Q 819+521 T 1043 \u001b[92m☑\u001b[0m 1043\n",
      "Q 457+748 T 1601 \u001b[92m☑\u001b[0m 1601\n",
      "Q 657+513 T 1071 \u001b[92m☑\u001b[0m 1071\n",
      "Q 13+06   T 91   \u001b[91m☒\u001b[0m 80  \n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 19s 428us/step - loss: 0.0204 - acc: 0.9939 - val_loss: 0.0143 - val_acc: 0.9954\n",
      "Q 724+952 T 686  \u001b[92m☑\u001b[0m 686 \n",
      "Q 515+571 T 690  \u001b[92m☑\u001b[0m 690 \n",
      "Q 937+776 T 1416 \u001b[92m☑\u001b[0m 1416\n",
      "Q 26+017  T 772  \u001b[91m☒\u001b[0m 872 \n",
      "Q 736+729 T 1564 \u001b[92m☑\u001b[0m 1564\n",
      "Q 902+374 T 682  \u001b[92m☑\u001b[0m 682 \n",
      "Q 062+444 T 704  \u001b[92m☑\u001b[0m 704 \n",
      "Q 356+081 T 833  \u001b[92m☑\u001b[0m 833 \n",
      "Q 976+001 T 779  \u001b[92m☑\u001b[0m 779 \n",
      "Q 713+635 T 853  \u001b[92m☑\u001b[0m 853 \n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 420us/step - loss: 0.0258 - acc: 0.9921 - val_loss: 0.0139 - val_acc: 0.9957\n",
      "Q 858+795 T 1455 \u001b[92m☑\u001b[0m 1455\n",
      "Q 019+348 T 1753 \u001b[92m☑\u001b[0m 1753\n",
      "Q 317+929 T 1642 \u001b[92m☑\u001b[0m 1642\n",
      "Q 703+631 T 443  \u001b[92m☑\u001b[0m 443 \n",
      "Q 4+179   T 975  \u001b[92m☑\u001b[0m 975 \n",
      "Q 152+306 T 854  \u001b[92m☑\u001b[0m 854 \n",
      "Q 239+676 T 1608 \u001b[92m☑\u001b[0m 1608\n",
      "Q 131+735 T 668  \u001b[92m☑\u001b[0m 668 \n",
      "Q 761+665 T 733  \u001b[92m☑\u001b[0m 733 \n",
      "Q 836+034 T 1068 \u001b[92m☑\u001b[0m 1068\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 419us/step - loss: 0.0171 - acc: 0.9949 - val_loss: 0.0557 - val_acc: 0.9817\n",
      "Q 957+439 T 1693 \u001b[92m☑\u001b[0m 1693\n",
      "Q 485+783 T 971  \u001b[92m☑\u001b[0m 971 \n",
      "Q 134+482 T 715  \u001b[92m☑\u001b[0m 715 \n",
      "Q 534+98  T 524  \u001b[92m☑\u001b[0m 524 \n",
      "Q 837+346 T 1381 \u001b[92m☑\u001b[0m 1381\n",
      "Q 564+271 T 637  \u001b[92m☑\u001b[0m 637 \n",
      "Q 712+448 T 1061 \u001b[92m☑\u001b[0m 1061\n",
      "Q 729+7   T 934  \u001b[92m☑\u001b[0m 934 \n",
      "Q 721+391 T 320  \u001b[92m☑\u001b[0m 320 \n",
      "Q 334+175 T 1004 \u001b[92m☑\u001b[0m 1004\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 19s 419us/step - loss: 0.0315 - acc: 0.9906 - val_loss: 0.0634 - val_acc: 0.9787\n",
      "Q 256+115 T 1163 \u001b[91m☒\u001b[0m 1173\n",
      "Q 117+537 T 1446 \u001b[92m☑\u001b[0m 1446\n",
      "Q 949+496 T 1643 \u001b[92m☑\u001b[0m 1643\n",
      "Q 149+06  T 1001 \u001b[92m☑\u001b[0m 1001\n",
      "Q 387+43  T 817  \u001b[92m☑\u001b[0m 817 \n",
      "Q 111+616 T 727  \u001b[92m☑\u001b[0m 727 \n",
      "Q 708+336 T 1440 \u001b[92m☑\u001b[0m 1440\n",
      "Q 85+68   T 144  \u001b[92m☑\u001b[0m 144 \n",
      "Q 628+94  T 875  \u001b[92m☑\u001b[0m 875 \n",
      "Q 64+284  T 528  \u001b[92m☑\u001b[0m 528 \n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "22976/45000 [==============>...............] - ETA: 9s - loss: 0.0208 - acc: 0.9941"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=32\n",
    "EPOCHS=100\n",
    "model.compile(optimizer='nadam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "for i in range(200):\n",
    "    model.fit(x=train_x, y=train_y, validation_data=(val_x, val_y),\n",
    "              batch_size=BATCH_SIZE, epochs=1)\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(val_x))\n",
    "        rowx, rowy = val_x[np.array([ind])], val_y[np.array([ind])]\n",
    "        preds = model.predict(rowx)\n",
    "        q = char_table.decode(rowx[0])\n",
    "        correct = char_table.decode(rowy[0])\n",
    "        guess = char_table.decode(preds[0], calc_argmax=True)\n",
    "        print('Q', q[::-1] if REVERSE else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下圖為以上架構的詳解, 圖源來自\n",
    "\n",
    "https://qiita.com/HotAllure/items/0045998971a48909853d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"pics/encoder.png\" width=\"50%\">\n",
    "<img style=\"float: right;\" src=\"pics/decoder.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
